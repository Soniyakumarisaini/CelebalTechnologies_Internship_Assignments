{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25553f70",
   "metadata": {},
   "source": [
    "Assignment Week 6 :-  Train multiple machine learning models and evaluate their performance using metrics such as accuracy, precision, recall, and F1-score. Implement hyperparameter tuning techniques like GridSearchCV and RandomizedSearchCV to optimize model parameters. Analyze the results to select the best-performing model.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b418ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Performance (Before Tuning):\n",
      "\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Logistic Regression  1.000000   1.000000  1.000000  1.000000\n",
      "1        Random Forest  1.000000   1.000000  1.000000  1.000000\n",
      "2                  SVM  1.000000   1.000000  1.000000  1.000000\n",
      "3                  KNN  0.944444   0.949383  0.944444  0.943604\n",
      "\n",
      "üèÜ Final Model Comparison (After Tuning):\n",
      "\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Logistic Regression  1.000000   1.000000  1.000000  1.000000\n",
      "1        Random Forest  1.000000   1.000000  1.000000  1.000000\n",
      "2                  SVM  1.000000   1.000000  1.000000  1.000000\n",
      "4  Tuned Random Forest  1.000000   1.000000  1.000000  1.000000\n",
      "5            Tuned SVM  1.000000   1.000000  1.000000  1.000000\n",
      "3                  KNN  0.944444   0.949383  0.944444  0.943604\n",
      "\n",
      "‚úÖ Best Performing Model: Logistic Regression with F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Load Wine Dataset\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# Preprocessing: Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Train and Evaluate Each Model\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìä Model Performance (Before Tuning):\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "# GridSearchCV for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10]\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=3, scoring='f1_weighted')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# RandomizedSearchCV for SVM\n",
    "param_dist_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "rand_svc = RandomizedSearchCV(SVC(), param_distributions=param_dist_svc, n_iter=10, cv=3, scoring='f1_weighted', random_state=42)\n",
    "rand_svc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Tuned Models\n",
    "tuned_models = {\n",
    "    \"Tuned Random Forest\": grid_rf.best_estimator_,\n",
    "    \"Tuned SVM\": rand_svc.best_estimator_\n",
    "}\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "# Final Results\n",
    "final_results_df = pd.DataFrame(results)\n",
    "final_sorted = final_results_df.sort_values(by='F1 Score', ascending=False)\n",
    "print(\"\\nüèÜ Final Model Comparison (After Tuning):\\n\")\n",
    "print(final_sorted)\n",
    "\n",
    "# Best Model Summary\n",
    "# F1-score (weighted) is preferred in multi-class classification like the wine dataset.\n",
    "best_model = final_sorted.iloc[0]\n",
    "print(f\"\\n‚úÖ Best Performing Model: {best_model['Model']} with F1 Score: {best_model['F1 Score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45f446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
